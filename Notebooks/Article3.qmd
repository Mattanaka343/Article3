---
title: "Cómo el Lenguaje Afecta Nuestras Emociones: Clasificación de Historias de Terror"
authors:
- Mateo Yañez-Tanaka
- Jorge Sánchez-Ponce
- Fernando Ramos-Valdez
- Fernando Pavía-González
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
    df-print: kable
  pdf:
    toc: true
    documentclass: article
    number-sections: true
    df-print: kable
    include-in-header: ../Resources/header.tex
editor: source
bibliography: ../Resources/references.bib
---

```{R}
#| include: false
knitr::opts_chunk$set(echo = FALSE)

```

## Abstract

Este proyecto tiene como propósito implementar un clasificador naïve Bayes para categorizar relatos de fenómenos paranormales recopilados en línea mediante técnicas de web scraping. La base de datos se construyó a partir de historias obtenidas del sitio Your Ghost Stories, en las cuales se registran eventos sobrenaturales narrados por usuarias y usuarios de diferentes regiones. Los relatos fueron procesados mediante técnicas de análisis de texto y transformados en representaciones vectoriales a través de matrices dispersas, que permiten capturar la frecuencia de palabras relevantes asociadas a cada tipo de evento. Posteriormente, se entrenaron modelos probabilísticos naïve Bayes, incluyendo variantes con distribución Poisson y Laplace smoothing, para evaluar su desempeño en tareas de clasificación binaria y multiclase. Los resultados fueron evaluados en términos de accuracy, precision, recall, F1-score y matriz de confusión, mostrando la pertinencia de los métodos probabilísticos en problemas de minería de texto, así como las limitaciones impuestas por la naturaleza de los datos.

## Introducción

El análisis de fenómenos paranormales ha sido tradicionalmente abordado desde una perspectiva anecdótica, donde los relatos recopilados representan experiencias subjetivas difíciles de sistematizar. Sin embargo, el auge del procesamiento de lenguaje natural (NLP) y la minería de texto ha abierto la posibilidad de estudiar este tipo de narrativas desde un enfoque cuantitativo. Una técnica particularmente útil para ello es el clasificador naïve Bayes, un modelo probabilístico que, a partir de supuestos de independencia condicional entre variables, permite categorizar textos en función de las características lingüísticas que presentan.

Para este proyecto, se construyó un conjunto de datos de relatos paranormales mediante web scraping del portal Your Ghost Stories, validando previamente la viabilidad legal y técnica de la recolección de información a través de la función paths_allowed() del paquete robotstxt en R. Cada historia fue procesada para extraer su título, lugar, tipo de evento y descripción completa, constituyendo la base de análisis. Posteriormente, el texto fue transformado en una matriz dispersa utilizando herramientas como tidytext y stringr, lo cual facilitó la vectorización de palabras y la eliminación de stop words.

El modelo naïve Bayes se entrenó inicialmente para clasificación multiclase y posteriormente para una clasificación dicotómica con el fin de evaluar diferencias en desempeño. Asimismo, se exploraron variantes del modelo utilizando distribución Poisson y Laplace smoothing, con la finalidad de mitigar los problemas derivados de los ceros frecuentes en los conteos de palabras. Finalmente, se aplicó validación cruzada para ajustar parámetros y seleccionar la configuración más adecuada. De esta manera, el presente trabajo no solo ejemplifica la aplicación de técnicas de NLP y aprendizaje automático en contextos no convencionales, sino que también muestra cómo estas herramientas pueden aportar un marco de análisis más riguroso para fenómenos que tradicionalmente se consideran del ámbito anecdótico o subjetivo.


## Metodología


## Aplicación

Para este proyecto se utilizaron las historias de terror contenidas en [*Your Ghost Stories*](https://www.yourghoststories.com/real-ghost-stories.php). Se decidió que se trataría únicamente con dos tipos de historias, aquellas que son sobre demonios, posesiones y exorcismos y aquellas que son sobre poltergeists y manifestaciones físicas. Para generar los datos que se usaron para el clasificador se hizo una técnica conocida como *web scraping* que nos permite recolectar el texto que contiene una página web y se recolectaron únicamente las descripciones, el tipo de historia del que se trata, el lugar donde ocurrió y el título del relato. Se recolectaron 200 histarias en total, 100 de cada categoría de modo que los datos estuvieran balnaceados.

```{R}
library(tidyverse)
library(tidytext)
library(rvest)
library(knitr)
library(tidyr)
library(dplyr)
library(robotstxt)
library(bnlearn)
source('../Scripts/StoryScrape.R')
set.seed(42)


html1 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1')
html2 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=2&page=1')

poltergeist_links = html2 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
poltergeist_links =  paste0('https://www.yourghoststories.com/', poltergeist_links)

possession_links = html1 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
possession_links =  paste0('https://www.yourghoststories.com/', possession_links)

possession_stories =  do.call(rbind, lapply(possession_links, StoryScrape))
poltergeist_stories = do.call(rbind, lapply(poltergeist_links, StoryScrape))

all_stories = rbind(possession_stories,poltergeist_stories)
```

Después de aplicar esta técnica se realizó un proceso conocido como *count vectorizer*, este se refiere a convertir cada palabra en una variable y asignarle un valor númerico. En este caso el valor numérico asignado es la cantidad de apariciones que tuvo esta palabra en el texto. Adicionalmente se eliminarán palabras comunes como *the*, *in*, *of*, y otras que no aportan información a la historia. 


### Análisis de Texto

Tras haberle aplciado este proceso a los datos, se ralizó un análisis del texto contenido en cada historia. Se comenzó por oservar las diez palabras más frecuentes en cada una para ver si es un buen indicador en las diferentes categorías. Este anáisis permitió notar lo siguiente: cada relato está marcado por vocablos específicos que refuerzan su temática y contexto narrativo. Por ejemplo, en *A Camp To Remember* destacan términos como *sheena*, *ate* y *camp*, que aluden directamente al escenario y protagonistas; en *Clash Of Personalities* predominan *apartment*, *door* y *porch*, que sitúan el relato en un entorno doméstico; mientras que en *A Future Fall* resaltan palabras como *church*, *demon* y *graveyard*, asociadas a lo religioso y lo sobrenatural. En conjunto, estos patrones sugieren que las palabras poco comunes funcionan como anclajes semánticos que construyen la atmósfera de cada historia, diferenciándolas entre sí y enfatizando elementos centrales (lugares, personajes o conceptos sobrenaturales) que definen el tono y la experiencia narrativa de lo paranormal.

```{R}
words = all_stories |> unnest_tokens(output = word, input = text)

top10 = words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = title, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable() 

graphs= words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  ungroup() |>
  filter(title %in% unique(title)[1:12]) |>
  ggplot(aes(y = reorder_within(word, n, title), x = n, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)

graphs
```

Otro factor que se consideró importante fue las combinaciones de palabras, en específico en pares (bigramas). Analizar esto puede ayudar a obtener una idea sobre cómo se construyen las historias, el tono que intentan dar y cómo caracterizan a sus personajes. En específico este análisis se utilizó para ver si hay alguna diferencia entre cómo se caracterizan los diferentes géneros en este tipo de historias. Para esto se separaron las palaras contiguas a los pronombres *"he"* y *"she"*. Después de *“she”* aparecen con mayor frecuencia verbos relacionados con procesos internos o de percepción como *"used"*, *"thought"* y *"heard"*, lo que sugiere una representación más introspectiva o reflexiva. En contraste, tras *“he”* predominan verbos de acción o resultado como got, would, felt y told, lo que proyecta una narrativa más activa o externa. En conjunto, estos resultados indican que el discurso tiende a construir a las mujeres como personajes que piensan, oyen o recuerdan, mientras que a los hombres se les vincula con acciones, decisiones o consecuencias, reforzando estereotipos de género en la forma en que se narran las experiencias.


```{R}
story_bigrams = all_stories |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  filter(!is.na(bigram))

pronouns = c("he", "she")

bigram_counts = story_bigrams |>
  count(bigram, sort = TRUE) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(word1 %in% pronouns) |>
  count(word1, word2, wt = n, sort = TRUE) |>
  rename(total = n)

word_ratios = bigram_counts |>
  group_by(word2) |>
  filter(sum(total) > 10) |>
  ungroup() |>
  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>
  arrange(word2) |>
  mutate(
    she = (she+1)/sum(she+1),
    he = (he+1)/sum(he+1),
    logratio = log(she / he, base = 2)
  ) |>
  arrange(desc(logratio))

word_ratios |>
  mutate(abslogratio = abs(logratio)) |>
  group_by(logratio < 0) |>
  top_n(15, abslogratio) |>
  ungroup() |>
  mutate(word = reorder(word2, logratio)) |>
  ggplot(aes(word, logratio, color = logratio < 0)) +
  geom_segment(
    aes(
      x = word, xend = word,
      y = 0, yend = logratio
    ),
    linewidth = 1.1, alpha = 0.6
  ) +
  geom_point(size = 3.5) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Aparición relativa después de 'she' comparado a 'he'",
    title = "Palabras contiguas a 'he' y 'she' en los textos",
  ) +
  scale_color_discrete(name = "", labels = c("Más 'she'", "Más 'he'")) +
  scale_y_continuous(
    breaks = seq(-3, 3),
    labels = c(
      "0.125x", "0.25x", "0.5x",
      "Same", "2x", "4x", "8x"
    )
  )
```

### Anális Sentimental

Una forma de analizar el sentimiento de un texto es considerarlo como una combinación de sus palabras individuales y el contenido sentimental del texto completo como la suma del contenido sentimental de cada palabra. Esta no es la única forma de abordar el análisis de sentimiento, pero es un enfoque frecuente que aprovecha naturalmente el ecosistema de herramientas de Tidy.

```{R}
install.packages("textdata")
library(textdata)
```

```{R}
sentiments <- get_sentiments("afinn")
sentiments
```

```{R}
bigram_counts |>
  left_join(sentiments, by = c("word2" = "word")) |>
  filter(!is.na(value)) |>
  mutate(sentiment = total * value) |>
  group_by(word1) |>
  arrange(desc(abs(sentiment))) |>
  slice_head(n = 10)
```

El análisis muestra un balance mixto entre palabras positivas y negativas, pero con una inclinación hacia lo negativo debido al peso de términos como died, que con cuatro apariciones alcanza un puntaje de -12 y se convierte en la palabra más influyente del conjunto. Aunque también se observan expresiones positivas como enjoys, laughed, loved o devoted, estas no logran contrarrestar por completo la carga negativa dominante. En conjunto, el texto refleja un tono general tendiente a lo negativo, matizado por algunos elementos positivos que aportan variabilidad al sentimiento global.

```{R}
spooky_matrix = words |>
  anti_join(stop_words) |>
  count(word, title, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = word, 
    values_from = n,
    values_fn = as.character,
    values_fill = "0"
    ) |>
  kable() 
```


## Conclusión
