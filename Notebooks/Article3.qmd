---
story_id: "Cómo el Lenguaje Afecta Nuestras Emociones: Clasificación de Historias de Terror"
authors:
- Mateo Yañez-Tanaka
- Jorge Sánchez-Ponce
- Fernando Ramos-Valdez
- Fernando Pavía-González
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
    df-print: kable
  pdf:
    toc: true
    documentclass: article
    number-sections: true
    df-print: kable
    include-in-header: ../Resources/header.tex
editor: source
bibliography: ../Resources/references.bib
---

```{R}
#| include: false
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```

## Abstract

Este proyecto tiene como propósito implementar un clasificador naïve Bayes para categorizar relatos de fenómenos paranormales recopilados en línea mediante técnicas de web scraping. La base de datos se construyó a partir de historias obtenidas del sitio Your Ghost Stories, en las cuales se registran eventos sobrenaturales narrados por usuarias y usuarios de diferentes regiones. Los relatos fueron procesados mediante técnicas de análisis de texto y transformados en representaciones vectoriales a través de matrices dispersas, que permiten capturar la frecuencia de palabras relevantes asociadas a cada tipo de evento. Posteriormente, se entrenaron modelos probabilísticos naïve Bayes, incluyendo variantes con distribución Poisson y Laplace smoothing, para evaluar su desempeño en tareas de clasificación binaria y multiclase. Los resultados fueron evaluados en términos de accuracy, precision, recall, F1-score y matriz de confusión, mostrando la pertinencia de los métodos probabilísticos en problemas de minería de texto, así como las limitaciones impuestas por la naturaleza de los datos.

## Introducción

El lenguaje que utilizamos al narrar historias refleja no solo información sobre los eventos que describimos, sino también patrones estructurales, elecciones léxicas y tonos emocionales que construyen la experiencia del lector. En el contexto de relatos de terror, estas características se vuelven particularmente relevantes, pues las palabras elegidas, las combinaciones sintácticas y la frecuencia de ciertos términos pueden diferenciar categorías de historias y moldear la percepción del lector.

Este proyecto se centra en el análisis cuantitativo del lenguaje en relatos de terror, utilizando técnicas de procesamiento de texto y aprendizaje automático para identificar patrones lingüísticos que distinguen entre historias sobre posesiones y exorcismos y aquellas sobre poltergeists y manifestaciones físicas. Se eligeron únicamente estas dos categrías debido a que estos tipos de eventos son conceptualmente bastante similares y diferenciar entre ellos podría ayudar a notar especificidades en el uso del lenguage. Se espera que con los resultados obtenidos por esta investigación se comprenda mejor como el lenguaje utilizado informa lo que se comunica y se encuentren correlaciones entre ciertos términos y la razón de la historia.

Invevstigaciones previas han mostrado que, 


## Metodología

Para este proyecto se utilizaron las redes bayesianas (BN) para generar un clasificador de Naïve Bayes. Este clasificador asume que el único nodo padre en el sistema es la clase y loos nodos hijos el resto de variables. También se asume que los nodos hijos no se relacionan entre ellos, esto genera una estructura del estilo
```{R}
dag = model2network('[Y][X1|Y][X2|Y][X3|Y][...|Y][Xn|Y]')
graphviz.plot(dag, shape = 'ellipse')
```
y nos permite generar la función de distribución global condicional $$f(y,x_1,x_2,\ldots, x_n) = f(y)\prod_{i=1}^nf_i(x_i\mid y)$$ Este tipo de red tamién nos permite clasificar usando la regla de bayes en la cuál para una nueva observación $\tilde{x}$ la probabilidad de $$\mathbb{P}(Y=k \mid X=\tilde{x}) = \frac{\mathbb{P}(X = \tilde{x} \mid Y=k)\mathbb{P}(Y=k)}{\mathbb{P}(X=\tilde{x})}$$ donde $\mathbb{P}(x) = \sum_{1}^k \mathbb{P}(X= \tilde{x} \mid Y= k)\mathbb{P}(Y=k)$. La clase asignada a cada observación es aquella con la mayor probabilidad a posteriori [@garrido2025modulo3]

Este proyecto también utilizó una técnica conocida como *web scrapping*, esta se refiere a recolectar datos de algún sitio web extrayendolos de su código fuente (usualmente html). [@parsehub_webscraping] Aunado a esto se utilizó una técnica de *tokenización* (asignación de valores numéricos a plabras) conocida como *count vectorizer* que consiste en transformar el texto en una matriz donde cada palabra única se convierte en una columna y cada documento en una fila. El valor numérico asignado a cada palabra corresponde a la cantidad de veces que aparece en ese documento. Finalmente se usaron técnicas de eliminación de *stop words* (palabras que no añaden información) para mantener únicamente las palabras que añaden al texto.[@medium_countvectorizer]

Todos los modelos computacionales usados para este proyecto fueron creados usando R un lenguaje de proggramacion para análisis estadístico. Se utilizaron los siguientes módulos:
- ```tidyverse``` Para manipulación de datos
- ```tidytext``` Para procesamiento de lenguaje natural
- ```tidymodels``` Para preprocesamiento de datos
- ```tidyr``` Para limpiar datos
- ```rvest``` Para realizar el *web scraping*
- ```knitr``` Para generar tablas y reportes dinámicos 
- ```dplyr``` Para manipulación de datos
- ```robotstxt``` Para verificar que  este permitido hacer *web scraping* en un sitio
- ```bnlearn``` Para modelar usando redes bayesianas 
- ```textdata``` Para tareas de procesamiento de lenguaje natural
- ```e1071``` Para modelos de *machine learning* 

## Aplicación

Para este proyecto se utilizaron las historias de terror contenidas en [*Your Ghost Stories*](https://www.yourghoststories.com/real-ghost-stories.php). Se decidió que se trataría únicamente con dos tipos de historias, aquellas que son sobre demonios, posesiones y exorcismos y aquellas que son sobre poltergeists y manifestaciones físicas. Para generar los datos que se usaron para el clasificador se hizo una técnica conocida como *web scraping* que nos permite recolectar el texto que contiene una página web y se recolectaron únicamente las descripciones, el tipo de historia del que se trata, el lugar donde ocurrió y el título del relato. Se recolectaron 200 histarias en total, 100 de cada categoría de modo que los datos estuvieran balnaceados.

```{R}
library(tidyverse)
library(tidytext)
library(tidymodels)
library(tidyr)
library(rvest)
library(knitr)
library(dplyr)
library(robotstxt)
library(bnlearn)
library(textdata)
library(e1071)
source('../Scripts/StoryScrape.R')
set.seed(42)


html1 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1')
html2 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=2&page=1')

poltergeist_links = html2 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
poltergeist_links =  paste0('https://www.yourghoststories.com/', poltergeist_links)

possession_links = html1 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
possession_links =  paste0('https://www.yourghoststories.com/', possession_links)

possession_stories =  do.call(rbind, lapply(possession_links, StoryScrape))
poltergeist_stories = do.call(rbind, lapply(poltergeist_links, StoryScrape))

all_stories = rbind(possession_stories,poltergeist_stories)
```

Después de aplicar esta técnica se realizó un proceso conocido como *count vectorizer*. Este consiste en transformar el texto en una matriz donde cada palabra única se convierte en una columna y cada documento en una fila. El valor numérico asignado a cada palabra corresponde a la cantidad de veces que aparece en ese documento. Adicionalmente, se eliminaron palabras comunes como *"the"*, *"in"*, *"of"*, y otras que no aportan información relevante a la historia.


### Análisis de Texto

Tras haberle aplciado este proceso a los datos, se ralizó un análisis del texto contenido en cada historia. Se comenzó por oservar las diez palabras más frecuentes en cada una para ver si es un buen indicador en las diferentes categorías. Este anáisis permitió notar lo siguiente: cada relato está marcado por vocablos específicos que refuerzan su temática y contexto narrativo. Por ejemplo, en *"A Camp To Remember"* destacan términos como *"sheena"*, *"ate"* y *"camp"*, que aluden directamente al escenario y protagonistas; en *"Clash Of Personalities"* predominan *"apartment"*, *"door"* y *"porch"*, que sitúan el relato en un entorno doméstico; mientras que en *"A Future Fall"* resaltan palabras como *"church"*, *"demon"* y *"graveyard"*, asociadas a lo religioso y lo sobrenatural. En conjunto, estos patrones sugieren que las palabras poco comunes funcionan como anclajes semánticos que construyen la atmósfera de cada historia, diferenciándolas entre sí y enfatizando elementos centrales (lugares, personajes o conceptos sobrenaturales) que definen el tono y la experiencia narrativa de lo paranormal.

```{R}
words = all_stories |> unnest_tokens(output = word, input = text)

top10 = words |>
  anti_join(stop_words) |>
  count(story_id, word, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = story_id, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable() 

graphs= words |>
  anti_join(stop_words) |>
  count(story_id, word, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 10) |>
  ungroup() |>
  filter(story_id %in% unique(story_id)[1:12]) |>
  ggplot(aes(y = reorder_within(word, n, story_id), x = n, fill = story_id)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~story_id, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)

graphs
```

Otro factor que se consideró importante fue las combinaciones de palabras, en específico en pares (bigramas). Analizar esto puede ayudar a obtener una idea sobre cómo se construyen las historias, el tono que intentan dar y cómo caracterizan a sus personajes. En específico este análisis se utilizó para ver si hay alguna diferencia entre cómo se caracterizan los diferentes géneros en este tipo de historias. Para esto se separaron las palaras contiguas a los pronombres *"he"* y *"she"*. Después de *“she”* aparecen con mayor frecuencia verbos relacionados con procesos internos o de percepción como *"used"*, *"thought"* y *"heard"*, lo que sugiere una representación más introspectiva o reflexiva. En contraste, tras *“he”* predominan verbos de acción o resultado como got, would, felt y told, lo que proyecta una narrativa más activa o externa. En conjunto, estos resultados indican que el discurso tiende a construir a las mujeres como personajes que piensan, oyen o recuerdan, mientras que a los hombres se les vincula con acciones, decisiones o consecuencias, reforzando estereotipos de género en la forma en que se narran las experiencias.

```{R}
story_bigrams = all_stories |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  filter(!is.na(bigram))

pronouns = c("he", "she")

bigram_counts = story_bigrams |>
  count(bigram, sort = TRUE) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(word1 %in% pronouns) |>
  count(word1, word2, wt = n, sort = TRUE) |>
  rename(total = n)

word_ratios = bigram_counts |>
  group_by(word2) |>
  filter(sum(total) > 10) |>
  ungroup() |>
  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>
  arrange(word2) |>
  mutate(
    she = (she+1)/sum(she+1),
    he = (he+1)/sum(he+1),
    logratio = log(she / he, base = 2)
  ) |>
  arrange(desc(logratio))

word_ratios |>
  mutate(abslogratio = abs(logratio)) |>
  group_by(logratio < 0) |>
  top_n(15, abslogratio) |>
  ungroup() |>
  mutate(word = reorder(word2, logratio)) |>
  ggplot(aes(word, logratio, color = logratio < 0)) +
  geom_segment(
    aes(
      x = word, xend = word,
      y = 0, yend = logratio
    ),
    linewidth = 1.1, alpha = 0.6
  ) +
  geom_point(size = 3.5) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Aparición relativa después de 'she' comparado a 'he'",
    story_id = "Palabras contiguas a 'he' y 'she' en los textos",
  ) +
  scale_color_discrete(name = "", labels = c("Más 'she'", "Más 'he'")) +
  scale_y_continuous(
    breaks = seq(-3, 3),
    labels = c(
      "0.125x", "0.25x", "0.5x",
      "Same", "2x", "4x", "8x"
    )
  )
```

Finalmente se anlaizó cómo las palabras determinan los sentimientoos implicados por una historia. Para esto se le asignó un valor numérico a cada una de las palabras representando su conotación emocional. El tono de cada historia fue considerado como la suma de los valores sentimentales de sus palabras. Este análisis mostró que la mayoría de las historias son significativamente más negativas que positivas con solo 20 títulos siendo mayormente positivos o neutros. Debido a la materia de las historias que se analizarón resultados de este índole eran de esperarse, las historias de terror tienden a ser bastante negativas y esto se exalta cuando se habla de posesiones, demonios, exorcismos, poltergeists y manifestaciones físicas.

```{R}
sentiments = get_sentiments("afinn")

story_sentiments = words |>
  anti_join(stop_words, by = "word") |>
  inner_join(sentiments, by = c("word" = "word")) |>
  group_by(story_id) |>
  summarise(sentiment_score = sum(value, na.rm = TRUE)) |>
  arrange(desc(sentiment_score))

story_sentiments
```


### Clasificación de Textos

Con los textos analizados se utilizó el moodelo de clasifación conocido como *Naïve Bayes* para categorizar historias nuevas en alguno de los eventos que incluímos (posesiones exorcismos y demonios o poltergeists y manifestaciones físicas). Para entrenar este modelo se dividieron los datos en 80% para entranmiento y 20% para pruebas. Este modelo resultó en la siguiente matriz de confusión
```{R}
set.seed(42)
words = all_stories |> mutate(full_text = paste(story_id,text)) |> unnest_tokens(output = word, input = full_text)

spooky_matrix = words |>
  anti_join(stop_words) |>
  count(word, story_id, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 20) |>
  pivot_wider(
    names_from = word, 
    values_from = n,
    values_fn = as.character,
    values_fill = "0"
    )

data = all_stories |> select(-text) |> rename(country_of_origin = location)|> rename(type_of_story=category) |> left_join(spooky_matrix,by = 'story_id')


data = data |> select(-story_id)


spooky_split = initial_split(data, prop = 0.8, strata = type_of_story)

training_data = training(spooky_split)
testing_data = testing(spooky_split)

classifier = naiveBayes(type_of_story ~ ., data = training_data, laplace = 1)

test_x = testing_data |> select(-type_of_story)
  
predictions = predict(classifier, test_x)

cm = table(Predecido = predictions, ValoresReales= testing_data$type_of_story)


cm
```

En esta se da a notar la capacidad de predicción del modelo con un total de 34 predicciones correctas de un total de 40 historias usadas para probar. Aunado a esto se calcularon los siguientes puntajes:
```{R}
metrics = data.frame(accuracy = c((16+18)/(40), (16+18)/(40)),
                     recall = c(16/20, 18/20),
                     precision = c(16/18, 18/22)
)

row.names(metrics) = c('Demons / Possessions / Exorcisms', 'Poltergeists / Physical Manifestations ')

metrics
```
El modelo presenta una exactitud (*accuracy*) de 85% siendo bastante bueno. Presenta una exhaustividad (*recall*) de 80% y 90% respectivamente lo cual evoca que no predice ninguna clase desproporcionadamente. Finalmente presenta precisiones de 89% y 82% por lo que se puede inferir que el valor de predicciones positivas se acercó mucho al real sustendo la aseveración que no sobrepredice ninguna clase 

## Conclusión
