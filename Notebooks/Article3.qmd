---
story_id: "Cómo el Lenguaje Afecta Nuestras Emociones: Clasificación de Historias de Terror"
authors:
- Mateo Yañez-Tanaka
- Jorge Sánchez-Ponce
- Fernando Ramos-Valdez
- Fernando Pavía-González
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
    df-print: kable
  pdf:
    toc: true
    documentclass: article
    number-sections: true
    df-print: kable
    include-in-header: ../Resources/header.tex
editor: source
bibliography: ../Resources/references.bib
---

```{R}
#| include: false
knitr::opts_chunk$set(echo = FALSE)

```

## Abstract

Este proyecto tiene como propósito implementar un clasificador naïve Bayes para categorizar relatos de fenómenos paranormales recopilados en línea mediante técnicas de web scraping. La base de datos se construyó a partir de historias obtenidas del sitio Your Ghost Stories, en las cuales se registran eventos sobrenaturales narrados por usuarias y usuarios de diferentes regiones. Los relatos fueron procesados mediante técnicas de análisis de texto y transformados en representaciones vectoriales a través de matrices dispersas, que permiten capturar la frecuencia de palabras relevantes asociadas a cada tipo de evento. Posteriormente, se entrenaron modelos probabilísticos naïve Bayes, incluyendo variantes con distribución Poisson y Laplace smoothing, para evaluar su desempeño en tareas de clasificación binaria y multiclase. Los resultados fueron evaluados en términos de accuracy, precision, recall, F1-score y matriz de confusión, mostrando la pertinencia de los métodos probabilísticos en problemas de minería de texto, así como las limitaciones impuestas por la naturaleza de los datos.

## Introducción

El análisis de fenómenos paranormales ha sido tradicionalmente abordado desde una perspectiva anecdótica, donde los relatos recopilados representan experiencias subjetivas difíciles de sistematizar. Sin embargo, el auge del procesamiento de lenguaje natural (NLP) y la minería de texto ha abierto la posibilidad de estudiar este tipo de narrativas desde un enfoque cuantitativo. Una técnica particularmente útil para ello es el clasificador naïve Bayes, un modelo probabilístico que, a partir de supuestos de independencia condicional entre variables, permite categorizar textos en función de las características lingüísticas que presentan.

Para este proyecto, se construyó un conjunto de datos de relatos paranormales mediante web scraping del portal Your Ghost Stories, validando previamente la viabilidad legal y técnica de la recolección de información a través de la función paths_allowed() del paquete robotstxt en R. Cada historia fue procesada para extraer su título, lugar, tipo de evento y descripción completa, constituyendo la base de análisis. Posteriormente, el texto fue transformado en una matriz dispersa utilizando herramientas como tidytext y stringr, lo cual facilitó la vectorización de palabras y la eliminación de stop words.

El modelo naïve Bayes se entrenó inicialmente para clasificación multiclase y posteriormente para una clasificación dicotómica con el fin de evaluar diferencias en desempeño. Asimismo, se exploraron variantes del modelo utilizando distribución Poisson y Laplace smoothing, con la finalidad de mitigar los problemas derivados de los ceros frecuentes en los conteos de palabras. Finalmente, se aplicó validación cruzada para ajustar parámetros y seleccionar la configuración más adecuada. De esta manera, el presente trabajo no solo ejemplifica la aplicación de técnicas de NLP y aprendizaje automático en contextos no convencionales, sino que también muestra cómo estas herramientas pueden aportar un marco de análisis más riguroso para fenómenos que tradicionalmente se consideran del ámbito anecdótico o subjetivo.


## Metodología


## Aplicación

Para este proyecto se utilizaron las historias de terror contenidas en [*Your Ghost Stories*](https://www.yourghoststories.com/real-ghost-stories.php). Se decidió que se trataría únicamente con dos tipos de historias, aquellas que son sobre demonios, posesiones y exorcismos y aquellas que son sobre poltergeists y manifestaciones físicas. Para generar los datos que se usaron para el clasificador se hizo una técnica conocida como *web scraping* que nos permite recolectar el texto que contiene una página web y se recolectaron únicamente las descripciones, el tipo de historia del que se trata, el lugar donde ocurrió y el título del relato. Se recolectaron 200 histarias en total, 100 de cada categoría de modo que los datos estuvieran balnaceados.

```{R}
library(tidyverse)
library(tidytext)
library(tidymodels)
library(tidyr)
library(rvest)
library(knitr)
library(dplyr)
library(robotstxt)
library(bnlearn)
library(textdata)
library(e1071)
source('../Scripts/StoryScrape.R')
set.seed(42)


html1 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1')
html2 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=2&page=1')

poltergeist_links = html2 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
poltergeist_links =  paste0('https://www.yourghoststories.com/', poltergeist_links)

possession_links = html1 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
possession_links =  paste0('https://www.yourghoststories.com/', possession_links)

possession_stories =  do.call(rbind, lapply(possession_links, StoryScrape))
poltergeist_stories = do.call(rbind, lapply(poltergeist_links, StoryScrape))

all_stories = rbind(possession_stories,poltergeist_stories)
```

Después de aplicar esta técnica se realizó un proceso conocido como *count vectorizer*. Este consiste en transformar el texto en una matriz donde cada palabra única se convierte en una columna y cada documento en una fila. El valor numérico asignado a cada palabra corresponde a la cantidad de veces que aparece en ese documento. Adicionalmente, se eliminaron palabras comunes como *"the"*, *"in"*, *"of"*, y otras que no aportan información relevante a la historia.


### Análisis de Texto

Tras haberle aplciado este proceso a los datos, se ralizó un análisis del texto contenido en cada historia. Se comenzó por oservar las diez palabras más frecuentes en cada una para ver si es un buen indicador en las diferentes categorías. Este anáisis permitió notar lo siguiente: cada relato está marcado por vocablos específicos que refuerzan su temática y contexto narrativo. Por ejemplo, en *"A Camp To Remember"* destacan términos como *"sheena"*, *"ate"* y *"camp"*, que aluden directamente al escenario y protagonistas; en *"Clash Of Personalities"* predominan *"apartment"*, *"door"* y *"porch"*, que sitúan el relato en un entorno doméstico; mientras que en *"A Future Fall"* resaltan palabras como *"church"*, *"demon"* y *"graveyard"*, asociadas a lo religioso y lo sobrenatural. En conjunto, estos patrones sugieren que las palabras poco comunes funcionan como anclajes semánticos que construyen la atmósfera de cada historia, diferenciándolas entre sí y enfatizando elementos centrales (lugares, personajes o conceptos sobrenaturales) que definen el tono y la experiencia narrativa de lo paranormal.

```{R}
words = all_stories |> unnest_tokens(output = word, input = text)

top10 = words |>
  anti_join(stop_words) |>
  count(story_id, word, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = story_id, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable() 

graphs= words |>
  anti_join(stop_words) |>
  count(story_id, word, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 10) |>
  ungroup() |>
  filter(story_id %in% unique(story_id)[1:12]) |>
  ggplot(aes(y = reorder_within(word, n, story_id), x = n, fill = story_id)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~story_id, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)

graphs
```

Otro factor que se consideró importante fue las combinaciones de palabras, en específico en pares (bigramas). Analizar esto puede ayudar a obtener una idea sobre cómo se construyen las historias, el tono que intentan dar y cómo caracterizan a sus personajes. En específico este análisis se utilizó para ver si hay alguna diferencia entre cómo se caracterizan los diferentes géneros en este tipo de historias. Para esto se separaron las palaras contiguas a los pronombres *"he"* y *"she"*. Después de *“she”* aparecen con mayor frecuencia verbos relacionados con procesos internos o de percepción como *"used"*, *"thought"* y *"heard"*, lo que sugiere una representación más introspectiva o reflexiva. En contraste, tras *“he”* predominan verbos de acción o resultado como got, would, felt y told, lo que proyecta una narrativa más activa o externa. En conjunto, estos resultados indican que el discurso tiende a construir a las mujeres como personajes que piensan, oyen o recuerdan, mientras que a los hombres se les vincula con acciones, decisiones o consecuencias, reforzando estereotipos de género en la forma en que se narran las experiencias.

```{R}
story_bigrams = all_stories |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  filter(!is.na(bigram))

pronouns = c("he", "she")

bigram_counts = story_bigrams |>
  count(bigram, sort = TRUE) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(word1 %in% pronouns) |>
  count(word1, word2, wt = n, sort = TRUE) |>
  rename(total = n)

word_ratios = bigram_counts |>
  group_by(word2) |>
  filter(sum(total) > 10) |>
  ungroup() |>
  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>
  arrange(word2) |>
  mutate(
    she = (she+1)/sum(she+1),
    he = (he+1)/sum(he+1),
    logratio = log(she / he, base = 2)
  ) |>
  arrange(desc(logratio))

word_ratios |>
  mutate(abslogratio = abs(logratio)) |>
  group_by(logratio < 0) |>
  top_n(15, abslogratio) |>
  ungroup() |>
  mutate(word = reorder(word2, logratio)) |>
  ggplot(aes(word, logratio, color = logratio < 0)) +
  geom_segment(
    aes(
      x = word, xend = word,
      y = 0, yend = logratio
    ),
    linewidth = 1.1, alpha = 0.6
  ) +
  geom_point(size = 3.5) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Aparición relativa después de 'she' comparado a 'he'",
    story_id = "Palabras contiguas a 'he' y 'she' en los textos",
  ) +
  scale_color_discrete(name = "", labels = c("Más 'she'", "Más 'he'")) +
  scale_y_continuous(
    breaks = seq(-3, 3),
    labels = c(
      "0.125x", "0.25x", "0.5x",
      "Same", "2x", "4x", "8x"
    )
  )
```

Finalmente se anlaizó cómo las palabras determinan los sentimientoos implicados por una historia. Para esto se le asignó un valor numérico a cada una de las palabras representando su conotación emocional. El tono de cada historia fue considerado como la suma de los valores sentimentales de sus palabras. Este análisis mostró que la mayoría de las historias son significativamente más negativas que positivas con solo 20 títulos siendo mayormente positivos o neutros. Debido a la materia de las historias que se analizarón resultados de este índole eran de esperarse, las historias de terror tienden a ser bastante negativas y esto se exalta cuando se habla de posesiones, demonios, exorcismos, poltergeists y manifestaciones físicas.

```{R}
sentiments = get_sentiments("afinn")

story_sentiments = words |>
  anti_join(stop_words, by = "word") |>
  inner_join(sentiments, by = c("word" = "word")) |>
  group_by(story_id) |>
  summarise(sentiment_score = sum(value, na.rm = TRUE)) |>
  arrange(desc(sentiment_score))

story_sentiments
```


### Clasificación de Textos

Con los textos analizados se utilizó el moodelo de clasifación conocido como *Naïve Bayes* para categorizar historias nuevas en alguno de los eventos que incluímos (posesiones exorcismos y demonios o poltergeists y manifestaciones físicas). Para entrenar este modelo se dividieron los datos en 80% para entranmiento y 20% para pruebas. Este modelo resultó en la siguiente matriz de confusión
```{R}
set.seed(42)
words = all_stories |> mutate(full_text = paste(story_id,text)) |> unnest_tokens(output = word, input = full_text)

spooky_matrix = words |>
  anti_join(stop_words) |>
  count(word, story_id, sort = TRUE) |>
  group_by(story_id) |>
  slice_head(n = 20) |>
  pivot_wider(
    names_from = word, 
    values_from = n,
    values_fn = as.character,
    values_fill = "0"
    )

data = all_stories |> select(-text) |> rename(country_of_origin = location)|> rename(type_of_story=category) |> left_join(spooky_matrix,by = 'story_id')


data = data |> select(-story_id)


spooky_split = initial_split(data, prop = 0.8, strata = type_of_story)

training_data = training(spooky_split)
testing_data = testing(spooky_split)

classifier = naiveBayes(type_of_story ~ ., data = training_data, laplace = 1)

test_x = testing_data |> select(-type_of_story)
  
predictions = predict(classifier, test_x)

cm = table(Predecido = predictions, ValoresReales= testing_data$type_of_story)


cm
```

En esta se da a notar la capacidad de predicción del modelo con un total de 34 predicciones correctas de un total de 40 historias usadas para probar. Aunado a esto se calcularon los siguientes puntajes:
```{R}
metrics = data.frame(accuracy = c((16+18)/(40), (16+18)/(40)),
                     recall = c(16/20, 18/20),
                     precision = c(16/18, 18/22)
)

row.names(metrics) = c('Demons / Possessions / Exorcisms', 'Poltergeists / Physical Manifestations ')

metrics
```
El modelo presenta una exactitud (*accuracy*) de 85% siendo bastante bueno. Presenta una exhaustividad (*recall*) de 80% y 90% respectivamente lo cual evoca que no predice ninguna clase desproporcionadamente. Finalmente presenta precisiones de 89% y 82% por lo que se puede inferir que el valor de predicciones positivas se acercó mucho al real sustendo la aseveración que no sobrepredice ninguna clase 

## Conclusión
