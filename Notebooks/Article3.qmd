---
title: "Cómo el Lenguaje Afecta Nuestras Emociones: Clasificación de Historias de Terror"
authors:
- Mateo Yañez-Tanaka
- Jorge Sánchez-Ponce
- Fernando Ramos-Valdez
- Fernando Pavía-González
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
    df-print: kable
  pdf:
    toc: true
    documentclass: article
    number-sections: true
    df-print: kable
    include-in-header: ../Resources/header.tex
editor: source
bibliography: ../Resources/references.bib
---

```{R}
#| include: false
knitr::opts_chunk$set(echo = FALSE)

```

## Abstract

Este proyecto tiene como propósito implementar un clasificador naïve Bayes para categorizar relatos de fenómenos paranormales recopilados en línea mediante técnicas de web scraping. La base de datos se construyó a partir de historias obtenidas del sitio Your Ghost Stories, en las cuales se registran eventos sobrenaturales narrados por usuarias y usuarios de diferentes regiones. Los relatos fueron procesados mediante técnicas de análisis de texto y transformados en representaciones vectoriales a través de matrices dispersas, que permiten capturar la frecuencia de palabras relevantes asociadas a cada tipo de evento. Posteriormente, se entrenaron modelos probabilísticos naïve Bayes, incluyendo variantes con distribución Poisson y Laplace smoothing, para evaluar su desempeño en tareas de clasificación binaria y multiclase. Los resultados fueron evaluados en términos de accuracy, precision, recall, F1-score y matriz de confusión, mostrando la pertinencia de los métodos probabilísticos en problemas de minería de texto, así como las limitaciones impuestas por la naturaleza de los datos.

## Introducción

El análisis de fenómenos paranormales ha sido tradicionalmente abordado desde una perspectiva anecdótica, donde los relatos recopilados representan experiencias subjetivas difíciles de sistematizar. Sin embargo, el auge del procesamiento de lenguaje natural (NLP) y la minería de texto ha abierto la posibilidad de estudiar este tipo de narrativas desde un enfoque cuantitativo. Una técnica particularmente útil para ello es el clasificador naïve Bayes, un modelo probabilístico que, a partir de supuestos de independencia condicional entre variables, permite categorizar textos en función de las características lingüísticas que presentan.

Para este proyecto, se construyó un conjunto de datos de relatos paranormales mediante web scraping del portal Your Ghost Stories, validando previamente la viabilidad legal y técnica de la recolección de información a través de la función paths_allowed() del paquete robotstxt en R. Cada historia fue procesada para extraer su título, lugar, tipo de evento y descripción completa, constituyendo la base de análisis. Posteriormente, el texto fue transformado en una matriz dispersa utilizando herramientas como tidytext y stringr, lo cual facilitó la vectorización de palabras y la eliminación de stop words.

El modelo naïve Bayes se entrenó inicialmente para clasificación multiclase y posteriormente para una clasificación dicotómica con el fin de evaluar diferencias en desempeño. Asimismo, se exploraron variantes del modelo utilizando distribución Poisson y Laplace smoothing, con la finalidad de mitigar los problemas derivados de los ceros frecuentes en los conteos de palabras. Finalmente, se aplicó validación cruzada para ajustar parámetros y seleccionar la configuración más adecuada. De esta manera, el presente trabajo no solo ejemplifica la aplicación de técnicas de NLP y aprendizaje automático en contextos no convencionales, sino que también muestra cómo estas herramientas pueden aportar un marco de análisis más riguroso para fenómenos que tradicionalmente se consideran del ámbito anecdótico o subjetivo.


## Metodología

## Aplicación

Para este proyecto se utilizaron las historias de terror contenidas en [*Your Ghost Stories*](https://www.yourghoststories.com/real-ghost-stories.php). Se decidió que se trataría únicamente con dos tipos de historias, aquellas que son sobre demonios, posesiones y exorcismos y aquellas que son sobre poltergeists y manifestaciones físicas. Para generar los datos que se usaron para el clasificador se hizo una técnica conocida como *web scraping* que nos permite recolectar el texto que contiene una página web y se recolectaron únicamente las descripciones, el tipo de historia del que se trata, el lugar donde ocurrió y el título del relato. Se recolectaron 200 histarias en total, 100 de cada categoría de modo que los datos estuvieran balnaceados.

```{R}
library(tidyverse)
library(tidytext)
library(rvest)
library(knitr)
library(tidyr)
library(dplyr)
library(robotstxt)
library(bnlearn)
source('../Scripts/StoryScrape.R')
set.seed(42)


html1 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1')
html2 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=2&page=1')

poltergeist_links = html2 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
poltergeist_links =  paste0('https://www.yourghoststories.com/', poltergeist_links)

possession_links = html1 |> html_elements('.rowlight, .rowdark') |> html_elements('a') |> html_attr('href')
possession_links =  paste0('https://www.yourghoststories.com/', possession_links)

possession_stories =  do.call(rbind, lapply(possession_links, StoryScrape))
poltergeist_stories = do.call(rbind, lapply(poltergeist_links, StoryScrape))

all_stories = rbind(possession_stories,poltergeist_stories)
```

Después de aplicar esta técnica se realizó un proceso conocido como *count vectorizer*, este se refiere a convertir cada palabra en una variable y asignarle un valor númerico. En este caso el valor numérico asignado es la cantidad de apariciones que tuvo esta palabra en el texto. Adicionalmente se eliminarán palabras comunes como *the*, *in*, *of*, y otras que no aportan información a la historia. 


### Análisis de Texto

Tras haberle aplciado este proceso a los datos, se ralizó un análisis del texto contenido en cada historia. Se comenzó por oservar las diez palabras más frecuentes en cada historia para ver si es un buen indicador común en los diferentes tipos de historias. Este análisis sin embargo no resultó muy útil debido a que las palabras usadas por los diferentes diferían bastante de historia a historia, sin embargo, se puede notar que palabras relacionadas a la biblia son decentemente relevantes para las historias de posesiones, demonios o exorcismos. 

```{R}
words = all_stories |> unnest_tokens(output = word, input = text)

top10 = words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = title, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable() 

graphs= words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  ungroup() |>
  filter(title %in% unique(title)[1:12]) |>
  ggplot(aes(y = reorder_within(word, n, title), x = n, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)

graphs
```

Otro factor que se consideró importante fue las combinaciones de palabras, en específico en pares. Analizar esto ayuda a obtener una idea sobre cómo se construyen las historias, el tono que intentan dar y cómo caracterizan a sus personajes. En específico este análisis se utilizó para ver si hay alguna diferencia entre cómo se caracterizan los diferentes géneros en este tipo de historias. Para esto se separaron las palaras contiguas a los pronombres *he* y *she*. Con esto se cooncluyó que los roles de los hombres en estas historias son 


```{R}
story_bigrams = all_stories |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  filter(!is.na(bigram))

pronouns = c("he", "she")

bigram_counts = story_bigrams |>
  count(bigram, sort = TRUE) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(word1 %in% pronouns) |>
  count(word1, word2, wt = n, sort = TRUE) |>
  rename(total = n)

word_ratios = bigram_counts |>
  group_by(word2) |>
  filter(sum(total) > 10) |>
  ungroup() |>
  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>
  arrange(word2) |>
  mutate(
    she = (she+1)/sum(she+1),
    he = (he+1)/sum(he+1),
    logratio = log(she / he, base = 2)
  ) |>
  arrange(desc(logratio))

word_ratios |>
  mutate(abslogratio = abs(logratio)) |>
  group_by(logratio < 0) |>
  top_n(15, abslogratio) |>
  ungroup() |>
  mutate(word = reorder(word2, logratio)) |>
  ggplot(aes(word, logratio, color = logratio < 0)) +
  geom_segment(
    aes(
      x = word, xend = word,
      y = 0, yend = logratio
    ),
    linewidth = 1.1, alpha = 0.6
  ) +
  geom_point(size = 3.5) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Aparición relativa después de 'she' comparado a 'he'",
    title = "Palabras contiguas a 'he' y 'she' en los textos",
  ) +
  scale_color_discrete(name = "", labels = c("Más 'she'", "Más 'he'")) +
  scale_y_continuous(
    breaks = seq(-3, 3),
    labels = c(
      "0.125x", "0.25x", "0.5x",
      "Same", "2x", "4x", "8x"
    )
  )
```








```{R}

```


```{R}
spooky_matrix = words |>
  anti_join(stop_words) |>
  count(word, title, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = word, 
    values_from = n,
    values_fn = as.character,
    values_fill = "0"
    ) |>
  kable() 
```


## Conclusión
