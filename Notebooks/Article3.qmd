---
title: "Cómo el Lenguaje Afecta Nuestras Emociones: Clasificacióon de Historias de Terror"
authors:
- Mateo Yañez-Tanaka
- Jorge Sánchez-Ponce
- Fernando Ramos-Valdez
- Fernando Pavía-González
format:
  html:
    toc: true
    html-math-method: katex
    embed-resources: true
    self-contained-math: true
    df-print: kable
  pdf:
    toc: true
    documentclass: article
    number-sections: true
    df-print: kable
    include-in-header: ../Resources/header.tex
editor: source
bibliography: ../Resources/references.bib
---
```{R}
#| include: false
knitr::opts_chunk$set(echo = FALSE)

```

## Abstract
Este proyecto tiene como propósito implementar un clasificador naïve Bayes para categorizar relatos de fenómenos paranormales recopilados en línea mediante técnicas de web scraping. La base de datos se construyó a partir de historias obtenidas del sitio Your Ghost Stories, en las cuales se registran eventos sobrenaturales narrados por usuarias y usuarios de diferentes regiones. Los relatos fueron procesados mediante técnicas de análisis de texto y transformados en representaciones vectoriales a través de matrices dispersas, que permiten capturar la frecuencia de palabras relevantes asociadas a cada tipo de evento. Posteriormente, se entrenaron modelos probabilísticos naïve Bayes, incluyendo variantes con distribución Poisson y Laplace smoothing, para evaluar su desempeño en tareas de clasificación binaria y multiclase. Los resultados fueron evaluados en términos de accuracy, precision, recall, F1-score y matriz de confusión, mostrando la pertinencia de los métodos probabilísticos en problemas de minería de texto, así como las limitaciones impuestas por la naturaleza de los datos.

## Introducción
El análisis de fenómenos paranormales ha sido tradicionalmente abordado desde una perspectiva anecdótica, donde los relatos recopilados representan experiencias subjetivas difíciles de sistematizar. Sin embargo, el auge del procesamiento de lenguaje natural (NLP) y la minería de texto ha abierto la posibilidad de estudiar este tipo de narrativas desde un enfoque cuantitativo. Una técnica particularmente útil para ello es el clasificador naïve Bayes, un modelo probabilístico que, a partir de supuestos de independencia condicional entre variables, permite categorizar textos en función de las características lingüísticas que presentan.

Para este proyecto, se construyó un conjunto de datos de relatos paranormales mediante web scraping del portal Your Ghost Stories, validando previamente la viabilidad legal y técnica de la recolección de información a través de la función paths_allowed() del paquete robotstxt en R. Cada historia fue procesada para extraer su título, lugar, tipo de evento y descripción completa, constituyendo la base de análisis. Posteriormente, el texto fue transformado en una matriz dispersa utilizando herramientas como tidytext y stringr, lo cual facilitó la vectorización de palabras y la eliminación de stop words.

El modelo naïve Bayes se entrenó inicialmente para clasificación multiclase y posteriormente para una clasificación dicotómica con el fin de evaluar diferencias en desempeño. Asimismo, se exploraron variantes del modelo utilizando distribución Poisson y Laplace smoothing, con la finalidad de mitigar los problemas derivados de los ceros frecuentes en los conteos de palabras. Finalmente, se aplicó validación cruzada para ajustar parámetros y seleccionar la configuración más adecuada. De esta manera, el presente trabajo no solo ejemplifica la aplicación de técnicas de NLP y aprendizaje automático en contextos no convencionales, sino que también muestra cómo estas herramientas pueden aportar un marco de análisis más riguroso para fenómenos que tradicionalmente se consideran del ámbito anecdótico o subjetivo.


## Metodología

## Aplicación

Para este proyecto se utilizaron las historias de terror contenidas en *[Your Ghost Stories](https://www.yourghoststories.com/real-ghost-stories.php)*. Se decidió que se trataría únicamente con dos tipos de historias, aquellas que son sobre demonios, posesiones o exorcismos o aquellas que son sore poltergeists o manifestaciones físicas. Para generar los datos que se usaron para el clasificador se hizo una técnica conocida como *web scraping* que nos permite recolectar el texto que contiene una página web y se recolectaron únicamente las descripciones, el tipo de historia del que se trata, el lugar donde ocurrió y el título del relato. Se recolectaron **50** histarias de ambas categorías de modo que los datos estuvieran bvalnaceados.

```{R}
library(robotstxt)
library(bnlearn)

paths_allowed("https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1")
```


```{R}
library(tidyverse)
library(rvest)
source('../Scripts/StoryScrape.R')

html1 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=10&page=1')
html2 = read_html('https://www.yourghoststories.com/ghost-stories-categories.php?category=2&page=1')

poltergeist_links = html2 |> html_elements('.rowlight a') |> html_attr('href')
poltergeist_links =  paste0('https://www.yourghoststories.com/', poltergeist_links)

possession_links = html1 |> html_elements('.rowlight a') |> html_attr('href')
possession_links =  paste0('https://www.yourghoststories.com/', possession_links)

possession_stories =  do.call(rbind, lapply(possession_links, StoryScrape))
poltergeist_stories = do.call(rbind, lapply(poltergeist_links, StoryScrape))

all_stories = rbind(possession_stories,poltergeist_stories)
```

```{R}
all_stories
```

✏️ Construyan una sparse matrix que incluya la frecuencia de cada palabra en los relatos scrapeados, donde cada renglón representa un relato diferente y donde las columnas son las diferentes palabras. Esta matriz también debe contener el tipo de evento paranormal. La función unnest_tokens() les puede ayudar. Consideren eliminar las palabras comunes en inglés a través de las stop words. Todo este proceso se conoce como un count vectorizer, que significa transformar texto a vectores.

```{R}
install.packages("tidytext")
install.packages("dplyr")
library(tidytext)
library(knitr)
library(janeaustenr) # install.packages("janeaustenr)
library(tidyr)
library(dplyr)
```


```{R}
common_words <- all_stories |>
  unnest_tokens(output = word, input = text) # token = "words" by default
```

```{R}
common_words |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  pivot_wider(
    names_from = title, 
    values_from = n,
    values_fn = as.character,
    values_fill = "Not in top 10"
    ) |>
  kable()
```

```{R}
stop_words
```

```{R}
common_words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  ungroup() |>
  #limitar a 10 titulos
  filter(title %in% unique(title)[1:10]) |>
  ggplot(aes(y = word, x = n, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, scales = "free") +
  labs(y = NULL)
```

```{R}
common_words |>
  anti_join(stop_words) |>
  count(title, word, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  ungroup() |>
  #limitar a 10 titulos
  filter(title %in% unique(title)[1:10]) |>
  ggplot(aes(y = reorder_within(word, n, title), x = n, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)
```


#Bigram frequencies
An n-gram is a contiguous series of words from a text; e.g., a bigram is a pair of words, with n = 2.

Split the text column into bigram tokens:
```{R}
story_bigrams <- all_stories |>
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |>
  filter(!is.na(bigram))

story_bigrams
```

```{R}
story_bigrams |>
  count(title, bigram, sort = TRUE) |>
  group_by(title) |>
  slice_head(n = 10) |>
  ungroup() |>
  #limitar a 10 titulos
  filter(title %in% unique(title)[1:10]) |>
  ggplot(aes(y = reorder_within(bigram, n, title), x = n, fill = title)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~title, scales = "free") +
  scale_y_reordered() +
  labs(y = NULL)
```

#Verbs that follow she or he
First, let’s define the pronouns of interest:

```{R}
pronouns <- c("he", "she")
```

Filter the dataset for bigrams that start with either “she” or “he” and calculate the number of times these bigrams appeared.

```{R}
bigram_counts <- story_bigrams |>
  count(bigram, sort = TRUE) |>
  separate(bigram, into = c("word1", "word2"), sep = " ") |>
  filter(word1 %in% pronouns) |>
  count(word1, word2, wt = n, sort = TRUE) |>
  rename(total = n)

bigram_counts
```

What can we do next to see if there is a difference in the types of verbs that follow “he” vs. “she”?
Which words have about the same likelihood of following “he” or “she” in the texts?

```{R}
word_ratios <- bigram_counts |>
  group_by(word2) |>
  filter(sum(total) > 10) |>
  ungroup() |>
  pivot_wider(names_from = word1, values_from = total, values_fill = 0) |>
  arrange(word2) |>
  mutate(
    she = (she+1)/sum(she+1),
    he = (he+1)/sum(he+1),
    logratio = log(she / he, base = 2)
  ) |>
  arrange(desc(logratio))

word_ratios
```

```{R}
word_ratios |> 
  arrange(abs(logratio))
```

```{R}
word_ratios |>
  mutate(abslogratio = abs(logratio)) |>
  group_by(logratio < 0) |>
  top_n(15, abslogratio) |>
  ungroup() |>
  mutate(word = reorder(word2, logratio)) |>
  ggplot(aes(word, logratio, color = logratio < 0)) +
  geom_segment(
    aes(
      x = word, xend = word,
      y = 0, yend = logratio
    ),
    linewidth = 1.1, alpha = 0.6
  ) +
  geom_point(size = 3.5) +
  coord_flip() +
  labs(
    x = NULL,
    y = "Relative appearance after 'she' compared to 'he'",
    title = "Words paired with 'he' and 'she' in the paranormal stories",
    subtitle = "Women use, think, and hear while men will, get, and feel"
  ) +
  scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) +
  scale_y_continuous(
    breaks = seq(-3, 3),
    labels = c(
      "0.125x", "0.25x", "0.5x",
      "Same", "2x", "4x", "8x"
    )
  )
```





## Conclusión


